#!/bin/bash
#SBATCH --job-name=save-submit
#SBATCH --cpus-per-gpu=8
#SBATCH --gpus-per-task=2
#SBATCH --mem-per-gpu=64G
#SBATCH --ntasks-per-node=1
#SBATCH --nodes=1

#SBATCH --output=R-%x.%j.out
#SBATCH --error=R-%x.%j.err

#SBATCH --partition=experimental
#SBATCH --account=sfglab
#SBATCH --time=00:05:00


source data/pascal.env

# https://gist.github.com/TengdaHan/1dd10d335c7ca6f13810fff41e809904
echo "NODELIST="${SLURM_NODELIST}
master_addr=$(scontrol show hostnames "$SLURM_JOB_NODELIST" | head -n 1)
export MASTER_ADDR=$master_addr
echo "MASTER_ADDR="$MASTER_ADDR
export MASTER_PORT=$((10000 + $RANDOM))
echo "MASTER_PORT="$MASTER_PORT
id=$RANDOM

srun torchrun \
--nnodes=1 \
--nproc_per_node=2 \
--rdzv_id $id \
--rdzv_backend c10d \
--rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \
main.py --no-is_plgrid -bs 8 -n 100 --log --save_dir saved-model --log_valid_loss_freq 200 --log_train_loss_freq 5 --early_stop 50